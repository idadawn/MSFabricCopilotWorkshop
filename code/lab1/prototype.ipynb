{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **ðŸ§ª  Lab 1 - Prototype**\n",
    "\n",
    "This notebook is about building a simple Microsoft Fabric-based Copilot application\n",
    "\n",
    "### **ðŸ”¥ Prerequirement**\n",
    "\n",
    "1. [Visual Studio Code](https://code.visualstudio.com/) or [GitHub Codespaces](https://github.com/features/codespaces)\n",
    "2. [Azure](https://azure.com/free) or [Azure for Student](https://aka.ms/studentgetazure)\n",
    "3. Apply [Azure OpenAI Service](https://customervoice.microsoft.com/Pages/ResponsePage.aspx?id=v4j5cvGGr0GRqy180BHbR7en2Ais5pxKtso_Pz4b1_xUOFA5Qk1UWDRBMjg0WFhPMkIzTzhKQ1dWNyQlQCN0PWcu)\n",
    "4. [.NET 7+](https://dotnet.microsoft.com/en-us/)\n",
    "5. [Docker](https://www.docker.com/)\n",
    "6. [Qdrant](https://qdrant.tech/)\n",
    "\n",
    "### **ðŸ“š Intro**\n",
    "\n",
    "We use Embeddings to inject relevant knowledge into the model of Azure OpenAI Services through the vector database. This is how we infuse magical skills. Learn from the following"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Introduce the related library of Semantic Kernel, and introduce the support of Semantic Kernel for Qdrant vector database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "dotnet_interactive": {
     "language": "csharp"
    },
    "polyglot_notebook": {
     "kernelName": "csharp"
    },
    "vscode": {
     "languageId": "polyglot-notebook"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div><div></div><div></div><div><strong>Installed Packages</strong><ul><li><span>Microsoft.SemanticKernel, 1.0.0-rc2</span></li><li><span>Microsoft.SemanticKernel.Connectors.Memory.Qdrant, 1.0.0-rc2</span></li></ul></div></div>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#r \"nuget: Microsoft.SemanticKernel, *-*\"\n",
    "#r \"nuget: Microsoft.SemanticKernel.Connectors.Memory.Qdrant, *-*\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "dotnet_interactive": {
     "language": "csharp"
    },
    "polyglot_notebook": {
     "kernelName": "csharp"
    },
    "vscode": {
     "languageId": "polyglot-notebook"
    }
   },
   "outputs": [],
   "source": [
    "using Microsoft.SemanticKernel;\n",
    "using Microsoft.SemanticKernel.Connectors.Memory.Qdrant;\n",
    "using Microsoft.SemanticKernel.Plugins.Memory;\n",
    "using Microsoft.SemanticKernel.Connectors.AI.OpenAI.TextEmbedding;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "dotnet_interactive": {
     "language": "csharp"
    },
    "polyglot_notebook": {
     "kernelName": "csharp"
    },
    "vscode": {
     "languageId": "polyglot-notebook"
    }
   },
   "outputs": [],
   "source": [
    "using System;\n",
    "using System.Collections.Generic;\n",
    "using System.Diagnostics;\n",
    "using System.IO;\n",
    "using System.Net.Http;\n",
    "using System.Text.Json;\n",
    "using System.Threading.Tasks;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A kernel in Semantic Kernel (SK) is an orchestrator of user problems. The kernel combines skills, memory and connectors to realize the user's intelligent expectations. In addition to configuring basic Azure OpenAI / OpenAI basic link strings / models / parameters / vector database, it can also pair related skills based on user requirements, integrate skills to form workflows, etc. \n",
    "\n",
    "The following example is to bind the Sementic Kernel to the gpt-3.5-turbo-16k and text-embedding-ada-002 models in Azure OpenAI Service, and connect to the locally assumed Qdrant vector database.\n",
    "\n",
    "**Note**\n",
    "\n",
    "*1. You need to bind the model of Azure OpenAI Service, which corresponds to the model you deployed in Azure AI Studio*\n",
    "\n",
    "*2. Azure OpenAI Service Endpoint and Key need to be obtained in Azure Portal*\n",
    "\n",
    "*3. The dimension of Azure OpenAI Service Embeddings is 1536, which is the default value, and you need to start the Qdrant service before this, please read [here](https://qdrant.tech/)*\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "dotnet_interactive": {
     "language": "csharp"
    },
    "polyglot_notebook": {
     "kernelName": "csharp"
    },
    "vscode": {
     "languageId": "polyglot-notebook"
    }
   },
   "outputs": [],
   "source": [
    "Kernel kernel = new KernelBuilder()\n",
    "            .WithAzureOpenAIChatCompletion(deploymentName:\"Your Azure OpenAI Services gpt-35-turbo-16k Deployment Name\",modelId:\"gpt-35-turbo-16k\",\"Your Azure OpenAI Services Endpoint\",\"Your Azure OpenAI Services API Key\")\n",
    "            .Build();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **ðŸ”‘ Key: Chunkings**\n",
    "\n",
    "With the expansion of model tokens by Azure OpenAI Service, chunking is no longer a problem, but we need to organize knowledge points is also an important step, Microsoft Fabric documents, headers and footers can be removed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "dotnet_interactive": {
     "language": "csharp"
    },
    "polyglot_notebook": {
     "kernelName": "csharp"
    },
    "vscode": {
     "languageId": "polyglot-notebook"
    }
   },
   "outputs": [],
   "source": [
    "string markdownFile = @\"../docs/microsoft-fabric-overview.md\";\n",
    "//string markdownFile = @\"../docs/data-science-overview.md\";\n",
    "// string markdownFile = @\"../docs/data-engineering-overview.md\";\n",
    "// string markdownFile = @\".../docs/data-factory-overview.md\";\n",
    "// string markdownFile = @\"../docs/data-warehousing.md\";\n",
    "// string markdownFile = @\"../docs/fabric-terminology.md\";\n",
    "//string markdownFile = @\"../docs/end-to-end-tutorials.md\";\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "dotnet_interactive": {
     "language": "csharp"
    },
    "polyglot_notebook": {
     "kernelName": "csharp"
    },
    "vscode": {
     "languageId": "polyglot-notebook"
    }
   },
   "outputs": [],
   "source": [
    "string learnContent = File.ReadAllText(markdownFile);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "dotnet_interactive": {
     "language": "csharp"
    },
    "polyglot_notebook": {
     "kernelName": "csharp"
    },
    "vscode": {
     "languageId": "polyglot-notebook"
    }
   },
   "outputs": [],
   "source": [
    "int content_start = learnContent.IndexOf(\"# \");\n",
    "int content_end = learnContent.IndexOf(\"## Next steps\");\n",
    "learnContent = learnContent.Substring(content_start,content_end - content_start) ;  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "dotnet_interactive": {
     "language": "csharp"
    },
    "polyglot_notebook": {
     "kernelName": "csharp"
    },
    "vscode": {
     "languageId": "polyglot-notebook"
    }
   },
   "outputs": [],
   "source": [
    "int chunkSize = learnContent.Length / 600;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "dotnet_interactive": {
     "language": "csharp"
    },
    "polyglot_notebook": {
     "kernelName": "csharp"
    },
    "vscode": {
     "languageId": "polyglot-notebook"
    }
   },
   "outputs": [],
   "source": [
    "var skillsDirectory = Path.Combine(\"..\", \"Plugins\");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "dotnet_interactive": {
     "language": "csharp"
    },
    "polyglot_notebook": {
     "kernelName": "csharp"
    },
    "vscode": {
     "languageId": "polyglot-notebook"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "../Plugins"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "skillsDirectory"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***Import Skill into the kernel, and inject magic through Prompt to extract relevant knowledge points***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "dotnet_interactive": {
     "language": "csharp"
    },
    "polyglot_notebook": {
     "kernelName": "csharp"
    },
    "vscode": {
     "languageId": "polyglot-notebook"
    }
   },
   "outputs": [],
   "source": [
    "var read_plugin = kernel.CreatePluginFromPromptDirectory(Path.Combine(skillsDirectory, \"ReadPlugin\"));\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "dotnet_interactive": {
     "language": "csharp"
    },
    "polyglot_notebook": {
     "kernelName": "csharp"
    },
    "vscode": {
     "languageId": "polyglot-notebook"
    }
   },
   "outputs": [],
   "source": [
    "public class KBContent\n",
    "{\n",
    "    public string KB { get; set; }\n",
    "    public string Content { get; set; }\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "dotnet_interactive": {
     "language": "csharp"
    },
    "polyglot_notebook": {
     "kernelName": "csharp"
    },
    "vscode": {
     "languageId": "polyglot-notebook"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<details open=\"open\" class=\"dni-treeview\"><summary><span class=\"dni-code-hint\"><code>[ {&quot;Name&quot;:&quot;KB&quot;,&quot;Description&quot;:&quot;Get KB Content&quot;,&quot;Metadata&quot;:{&quot;Name&quot;:&quot;KB&quot;,&quot;PluginName&quot;:null,&quot;Description&quot;:&quot;Get KB Content&quot;,&quot;Parameters&quot;:[],&quot;ReturnParameter&quot;:{&quot;Description&quot;:&quot;&quot;,&quot;ParameterType&quot;:null,&quot;Schema&quot;:null}}} ]</code></span></summary><div><table><thead><tr></tr></thead><tbody><tr><td>Name</td><td><div class=\"dni-plaintext\"><pre>ReadPlugin</pre></div></td></tr><tr><td>Description</td><td><div class=\"dni-plaintext\"><pre></pre></div></td></tr><tr><td>FunctionCount</td><td><div class=\"dni-plaintext\"><pre>1</pre></div></td></tr><tr><td><i>(values)</i></td><td><table><thead><tr><th><i>index</i></th><th>value</th></tr></thead><tbody><tr><td>0</td><td><details class=\"dni-treeview\"><summary><span class=\"dni-code-hint\"><code>{&quot;Name&quot;:&quot;KB&quot;,&quot;Description&quot;:&quot;Get KB Content&quot;,&quot;Metadata&quot;:{&quot;Name&quot;:&quot;KB&quot;,&quot;PluginName&quot;:null,&quot;Description&quot;:&quot;Get KB Content&quot;,&quot;Parameters&quot;:[],&quot;ReturnParameter&quot;:{&quot;Description&quot;:&quot;&quot;,&quot;ParameterType&quot;:null,&quot;Schema&quot;:null}}}</code></span></summary><div><table><thead><tr></tr></thead><tbody><tr><td>Name</td><td><div class=\"dni-plaintext\"><pre>KB</pre></div></td></tr><tr><td>Description</td><td><div class=\"dni-plaintext\"><pre>Get KB Content</pre></div></td></tr><tr><td>Metadata</td><td><details class=\"dni-treeview\"><summary><span class=\"dni-code-hint\"><code>Microsoft.SemanticKernel.KernelFunctionMetadata</code></span></summary><div><table><thead><tr></tr></thead><tbody><tr><td>Name</td><td><div class=\"dni-plaintext\"><pre>KB</pre></div></td></tr><tr><td>PluginName</td><td><div class=\"dni-plaintext\"><pre>&lt;null&gt;</pre></div></td></tr><tr><td>Description</td><td><div class=\"dni-plaintext\"><pre>Get KB Content</pre></div></td></tr><tr><td>Parameters</td><td><i>(empty)</i></td></tr><tr><td>ReturnParameter</td><td><details class=\"dni-treeview\"><summary><span class=\"dni-code-hint\"><code>Microsoft.SemanticKernel.KernelReturnParameterMetadata</code></span></summary><div><table><thead><tr></tr></thead><tbody><tr><td>Description</td><td><div class=\"dni-plaintext\"><pre></pre></div></td></tr><tr><td>ParameterType</td><td><div class=\"dni-plaintext\"><pre>&lt;null&gt;</pre></div></td></tr><tr><td>Schema</td><td><div class=\"dni-plaintext\"><pre>&lt;null&gt;</pre></div></td></tr></tbody></table></div></details></td></tr></tbody></table></div></details></td></tr></tbody></table></div></details></td></tr></tbody></table></td></tr></tbody></table></div></details><style>\r\n",
       ".dni-code-hint {\r\n",
       "    font-style: italic;\r\n",
       "    overflow: hidden;\r\n",
       "    white-space: nowrap;\r\n",
       "}\r\n",
       ".dni-treeview {\r\n",
       "    white-space: nowrap;\r\n",
       "}\r\n",
       ".dni-treeview td {\r\n",
       "    vertical-align: top;\r\n",
       "    text-align: start;\r\n",
       "}\r\n",
       "details.dni-treeview {\r\n",
       "    padding-left: 1em;\r\n",
       "}\r\n",
       "table td {\r\n",
       "    text-align: start;\r\n",
       "}\r\n",
       "table tr { \r\n",
       "    vertical-align: top; \r\n",
       "    margin: 0em 0px;\r\n",
       "}\r\n",
       "table tr td pre \r\n",
       "{ \r\n",
       "    vertical-align: top !important; \r\n",
       "    margin: 0em 0px !important;\r\n",
       "} \r\n",
       "table th {\r\n",
       "    text-align: start;\r\n",
       "}\r\n",
       "</style>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "read_plugin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "dotnet_interactive": {
     "language": "csharp"
    },
    "polyglot_notebook": {
     "kernelName": "csharp"
    },
    "vscode": {
     "languageId": "polyglot-notebook"
    }
   },
   "outputs": [],
   "source": [
    "public async Task<string> GetKBContent(Kernel kernel,string content)\n",
    "{\n",
    "    var kbContent = await kernel.InvokeAsync(read_plugin[\"KB\"],new(content));\n",
    "\n",
    "    return kbContent.ToString();\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "dotnet_interactive": {
     "language": "csharp"
    },
    "polyglot_notebook": {
     "kernelName": "csharp"
    },
    "vscode": {
     "languageId": "polyglot-notebook"
    }
   },
   "outputs": [],
   "source": [
    "bool checkStr = false;\n",
    "string kbContent = \"\";\n",
    "var kbList = new List<KBContent>();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "dotnet_interactive": {
     "language": "csharp"
    },
    "polyglot_notebook": {
     "kernelName": "csharp"
    },
    "vscode": {
     "languageId": "polyglot-notebook"
    }
   },
   "outputs": [],
   "source": [
    "kbContent = await GetKBContent(kernel,learnContent.Replace(\"\\\\\",\"\\\\\\\\\").Replace(\"\\\"\",\"\\'\").Replace(\":::\",\"\").Replace(\"\\n\",\"\"));"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "dotnet_interactive": {
     "language": "csharp"
    },
    "polyglot_notebook": {
     "kernelName": "csharp"
    },
    "vscode": {
     "languageId": "polyglot-notebook"
    }
   },
   "outputs": [],
   "source": [
    "//string setKBContent = kbContent.Replace(\"[OUTPUT]\",\"\").Replace(\"[END OUTPUT]\",\"\").Trim();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Through Prompt, we extract the content of knowledge points into JSON format, which is convenient for us to import into the relevant vector database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "dotnet_interactive": {
     "language": "csharp"
    },
    "polyglot_notebook": {
     "kernelName": "csharp"
    },
    "vscode": {
     "languageId": "polyglot-notebook"
    }
   },
   "outputs": [],
   "source": [
    "int pos = 0;\n",
    "if(kbContent.IndexOf(\"[OUTPUT]\")>-1)\n",
    "    pos =  kbContent.IndexOf(\"[OUTPUT]\");\n",
    "string setKBContent = kbContent.Substring(pos).Replace(\"[OUTPUT]\",\"\").Replace(\"[END OUTPUT]\",\"\").Trim();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "dotnet_interactive": {
     "language": "csharp"
    },
    "polyglot_notebook": {
     "kernelName": "csharp"
    },
    "vscode": {
     "languageId": "polyglot-notebook"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{\"KB\": \"What is Microsoft Fabric?\", \"Content\": \"Microsoft Fabric is an all-in-one analytics solution for enterprises that covers everything from data movement to data science, Real-Time Analytics, and business intelligence. It offers a comprehensive suite of services, including data lake, data engineering, and data integration, all in one place.With Fabric, you don't need to piece together different services from multiple vendors. Instead, you can enjoy a highly integrated, end-to-end, and easy-to-use product that is designed to simplify your analytics needs.The platform is built on a foundation of Software as a Service (SaaS), which takes simplicity and integration to a whole new level.\"}, {\"KB\": \"SaaS foundation\", \"Content\": \"Microsoft Fabric brings together new and existing components from Power BI, Azure Synapse, and Azure Data Explorer into a single integrated environment. These components are then presented in various customized user experiences.Fabric brings together experiences such as Data Engineering, Data Factory, Data Science, Data Warehouse, Real-Time Analytics, and Power BI onto a shared SaaS foundation. This integration provides the following advantages:- An extensive range of deeply integrated analytics in the industry.- Shared experiences across experiences that are familiar and easy to learn.- Developers can easily access and reuse all assets.- A unified data lake that allows you to retain the data where it is while using your preferred analytics tools.- Centralized administration and governance across all experiences.With the Microsoft Fabric SaaS experience, all the data and the services are seamlessly integrated. IT teams can centrally configure core enterprise capabilities and permissions are automatically applied across all the underlying services. Additionally, data sensitivity labels are inherited automatically across the items in the suite.Fabric allows creators to concentrate on producing their best work, freeing them from the need to integrate, manage, or understand the underlying infrastructure that supports the experience.\"}, {\"KB\": \"Components of Microsoft Fabric\", \"Content\": \"Microsoft Fabric offers the comprehensive set of analytics experiences designed to work together seamlessly. Each experience is tailored to a specific persona and a specific task. Fabric includes industry-leading experiences in the following categories for an end-to-end analytical need.- **Data Engineering** - Data Engineering experience provides a world class Spark platform with great authoring experiences, enabling data engineers to perform large scale data transformation and democratize data through the lakehouse. Microsoft Fabric Spark's integration with Data Factory enables notebooks and spark jobs to be scheduled and orchestrated. For more information, see [What is Data engineering in Microsoft Fabric?](../data-engineering/data-engineering-overview.md)- **Data Factory** - Azure Data Factory combines the simplicity of Power Query with the scale and power of Azure Data Factory. You can use more than 200 native connectors to connect to data sources on-premises and in the cloud. For more information, see [What is Data Factory in Microsoft Fabric?](../data-factory/data-factory-overview.md)- **Data Science** - Data Science experience enables you to build, deploy, and operationalize machine learning models seamlessly within your Fabric experience. It integrates with Azure Machine Learning to provide built-in experiment tracking and model registry. Data scientists are empowered to enrich organizational data with predictions and allow business analysts to integrate those predictions into their BI reports. This way it shifts from descriptive to predictive insights. For more information, see [What is Data science in Microsoft Fabric?](../data-science/data-science-overview.md)- **Data Warehouse** - Data Warehouse experience provides industry leading SQL performance and scale. It fully separates compute from storage, enabling independent scaling of both the components. Additionally, it natively stores data in the open Delta Lake format. For more information, see [What is data warehousing in Microsoft Fabric?](../data-warehouse/data-warehousing.md)- **Real-Time Analytics** - Observational data, which is collected from various sources such as apps, IoT devices, human interactions, and so many more. It's currently the fastest growing data category. This data is often semi-structured in formats like JSON or Text. It comes in at high volume, with shifting schemas. These characteristics make it hard for traditional data warehousing platforms to work with. Real-Time Analytics is best in class engine for observational data analytics. For more information, see [What is Real-Time Analytics in Fabric?](../real-time-analytics/overview.md)- **Power BI** - Power BI is the world's leading Business Intelligence platform. It ensures that business owners can access all the data in Fabric quickly and intuitively to make better decisions with data. For more information, see [What is Power BI?](/power-bi/fundamentals/power-bi-overview)Fabric brings together all these experiences into a unified platform to offer the most comprehensive big data analytics platform in the industry.Microsoft Fabric enables organizations, and individuals, to turn large and complex data repositories into actionable workloads and analytics, and is an implementation of data mesh architecture. To learn more about data mesh, visit the article that explains [data mesh architecture](/azure/cloud-adoption-framework/scenarios/cloud-scale-analytics/architectures/what-is-data-mesh).\"}, {\"KB\": \"OneLake and lakehouse - the unification of lakehouses\", \"Content\": \"The Microsoft Fabric platform unifies the OneLake and lakehouse architecture across the enterprises.OneLakeThe data lake is the foundation on which all the Fabric services are built. Microsoft Fabric Lake is also known as [OneLake](../onelake/onelake-overview.md). It's built into the Fabric service and provides a unified location to store all organizational data where the experiences operate.OneLake is built on top of ADLS (Azure Data Lake Storage) Gen2. It provides a single SaaS experience and a tenant-wide store for data that serves both professional and citizen developers. The OneLake SaaS experience simplifies the experiences, eliminating the need for users to understand any infrastructure concepts such as resource groups, RBAC (Role-Based Access Control), Azure Resource Manager, redundancy, or regions. Additionally it doesn't require the user to even have an Azure account.OneLake eliminates today's pervasive and chaotic data silos, which individual developers create when they provision and configure their own isolated storage accounts. Instead, OneLake provides a single, unified storage system for all developers, where discovery and data sharing is trivial and compliance with policy and security settings are enforced centrally and uniformly. For more information, see [What is OneLake?](../onelake/onelake-overview.md)Organizational structure of OneLake and lakehouseOneLake is hierarchical in nature to simplify management across your organization. It's built into Microsoft Fabric and there's no requirement for any up-front provisioning. There's only one OneLake per tenant and it provides a single-pane-of-glass file-system namespace that spans across users, regions and even clouds. The data in OneLake is divided into manageable containers for easy handling.The tenant maps to the root of OneLake and is at the top level of the hierarchy. You can create any number of workspaces within a tenant, which can be thought of as folders.The following image shows the various Fabric items where data is stored. It's an example of how various items within Fabric would store data inside OneLake. As displayed, you can create multiple workspaces within a tenant, create multiple lakehouses within each workspace. A lakehouse is a collection of files, folders, and tables that represents a database over a data lake. To learn more, see [What is a lakehouse?](../data-engineering/lakehouse-overview.md).Every developer and business unit in the tenant can instantly create their own workspaces in OneLake. They can ingest data into their own lakehouses, start processing, analyzing, and collaborating on the data, just like OneDrive in Office.All the Microsoft Fabric compute experiences are prewired to OneLake, just like the Office applications are prewired to use the organizational OneDrive. The experiences such as Data Engineering, Data Warehouse, Data Factory, Power BI, and Real-Time Analytics use OneLake as their native store. They don't need any extra configuration.OneLake is designed to allow instant mounting of existing PaaS storage accounts into OneLake with the [Shortcut](../onelake/onelake-shortcuts.md) feature. There's no need to migrate or move any of the existing data. Using shortcuts, you can access the data stored in Azure Data Lake Storage.Additionally, shortcuts allow you to easily share data between users and applications without moving or duplicating information. The shortcut capability extends to other storage systems, allowing you to compose and analyze data across clouds with transparent, intelligent caching that reduces egress costs and brings data closer to compute.\"}]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "setKBContent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "dotnet_interactive": {
     "language": "csharp"
    },
    "polyglot_notebook": {
     "kernelName": "csharp"
    },
    "vscode": {
     "languageId": "polyglot-notebook"
    }
   },
   "outputs": [],
   "source": [
    "var jsonKBContent = System.Text.Json.JsonSerializer.Deserialize<List<KBContent>>(setKBContent);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "dotnet_interactive": {
     "language": "csharp"
    },
    "polyglot_notebook": {
     "kernelName": "csharp"
    },
    "vscode": {
     "languageId": "polyglot-notebook"
    }
   },
   "outputs": [],
   "source": [
    "foreach(var item in jsonKBContent)\n",
    "{\n",
    "    kbList.Add(item);\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The token is added or we donâ€™t need to split the content, but sometimes there are unexpected situations, you need to intercept the content, segment and interact with the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "dotnet_interactive": {
     "language": "csharp"
    },
    "polyglot_notebook": {
     "kernelName": "csharp"
    },
    "vscode": {
     "languageId": "polyglot-notebook"
    }
   },
   "outputs": [],
   "source": [
    "// for(int i = 0; i < chunkSize+1; i++)\n",
    "// {\n",
    "                 \n",
    "//     if(checkStr)\n",
    "//     {\n",
    "//                //Console.WriteLine(strTmp);\n",
    "//         kbContent = await GetKBContent(kernel,learnContent.Substring(i*600).Replace(\"\\\\\",\"\\\\\\\\\").Replace(\"\\\"\",\"\\'\").Replace(\":::\",\"\"));\n",
    "//     }\n",
    "//     else\n",
    "//     {\n",
    "//         // strTmp = saveContent.Substring(i*600);\n",
    "//                //Console.WriteLine(strTmp.Substring(0,600));\n",
    "//         kbContent = await GetKBContent(kernel,learnContent.Substring(i*600,600).Replace(\"\\\\\",\"\\\\\\\\\").Replace(\"\\\"\",\"\\'\").Replace(\":::\",\"\"));\n",
    "//     }\n",
    "\n",
    "\n",
    "//     string setKBContent = kbContent.Replace(\"[OUTPUT]\",\"\").Replace(\"[END OUTPUT]\",\"\").Trim();\n",
    "\n",
    "\n",
    "//     Console.WriteLine(setKBContent);\n",
    "\n",
    "\n",
    "//     var jsonKBContent = System.Text.Json.JsonSerializer.Deserialize<List<KBContent>>(setKBContent);\n",
    "\n",
    "//     foreach(var item in jsonKBContent)\n",
    "//     {\n",
    "//         kbList.Add(item);\n",
    "//     }\n",
    "\n",
    "//     if(i!=chunkSize)\n",
    "//     {\n",
    "\n",
    "//         string strTmp = learnContent.Substring((i+1)*600);\n",
    "\n",
    "//         if(strTmp.Length <= 600)\n",
    "//             checkStr = true;\n",
    "//         else\n",
    "//             checkStr = false;\n",
    "//     }\n",
    "\n",
    "// }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "dotnet_interactive": {
     "language": "csharp"
    },
    "polyglot_notebook": {
     "kernelName": "csharp"
    },
    "vscode": {
     "languageId": "polyglot-notebook"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table><thead><tr><th><i>index</i></th><th>value</th></tr></thead><tbody><tr><td>0</td><td><details class=\"dni-treeview\"><summary><span class=\"dni-code-hint\"><code>Submission#12+KBContent</code></span></summary><div><table><thead><tr></tr></thead><tbody><tr><td>KB</td><td><div class=\"dni-plaintext\"><pre>What is Microsoft Fabric?</pre></div></td></tr><tr><td>Content</td><td><div class=\"dni-plaintext\"><pre>Microsoft Fabric is an all-in-one analytics solution for enterprises that covers everything from data movement to data science, Real-Time Analytics, and business intelligence. It offers a comprehensive suite of services, including data lake, data engineering, and data integration, all in one place.With Fabric, you don&#39;t need to piece together different services from multiple vendors. Instead, you can enjoy a highly integrated, end-to-end, and easy-to-use product that is designed to simplify your analytics needs.The platform is built on a foundation of Software as a Service (SaaS), which takes simplicity and integration to a whole new level.</pre></div></td></tr></tbody></table></div></details></td></tr><tr><td>1</td><td><details class=\"dni-treeview\"><summary><span class=\"dni-code-hint\"><code>Submission#12+KBContent</code></span></summary><div><table><thead><tr></tr></thead><tbody><tr><td>KB</td><td><div class=\"dni-plaintext\"><pre>SaaS foundation</pre></div></td></tr><tr><td>Content</td><td><div class=\"dni-plaintext\"><pre>Microsoft Fabric brings together new and existing components from Power BI, Azure Synapse, and Azure Data Explorer into a single integrated environment. These components are then presented in various customized user experiences.Fabric brings together experiences such as Data Engineering, Data Factory, Data Science, Data Warehouse, Real-Time Analytics, and Power BI onto a shared SaaS foundation. This integration provides the following advantages:- An extensive range of deeply integrated analytics in the industry.- Shared experiences across experiences that are familiar and easy to learn.- Developers can easily access and reuse all assets.- A unified data lake that allows you to retain the data where it is while using your preferred analytics tools.- Centralized administration and governance across all experiences.With the Microsoft Fabric SaaS experience, all the data and the services are seamlessly integrated. IT teams can centrally configure core enterprise capabilities and permissions are automatically applied across all the underlying services. Additionally, data sensitivity labels are inherited automatically across the items in the suite.Fabric allows creators to concentrate on producing their best work, freeing them from the need to integrate, manage, or understand the underlying infrastructure that supports the experience.</pre></div></td></tr></tbody></table></div></details></td></tr><tr><td>2</td><td><details class=\"dni-treeview\"><summary><span class=\"dni-code-hint\"><code>Submission#12+KBContent</code></span></summary><div><table><thead><tr></tr></thead><tbody><tr><td>KB</td><td><div class=\"dni-plaintext\"><pre>Components of Microsoft Fabric</pre></div></td></tr><tr><td>Content</td><td><div class=\"dni-plaintext\"><pre>Microsoft Fabric offers the comprehensive set of analytics experiences designed to work together seamlessly. Each experience is tailored to a specific persona and a specific task. Fabric includes industry-leading experiences in the following categories for an end-to-end analytical need.- **Data Engineering** - Data Engineering experience provides a world class Spark platform with great authoring experiences, enabling data engineers to perform large scale data transformation and democratize data through the lakehouse. Microsoft Fabric Spark&#39;s integration with Data Factory enables notebooks and spark jobs to be scheduled and orchestrated. For more information, see [What is Data engineering in Microsoft Fabric?](../data-engineering/data-engineering-overview.md)- **Data Factory** - Azure Data Factory combines the simplicity of Power Query with the scale and power of Azure Data Factory. You can use more than 200 native connectors to connect to data sources on-premises and in the cloud. For more information, see [What is Data Factory in Microsoft Fabric?](../data-factory/data-factory-overview.md)- **Data Science** - Data Science experience enables you to build, deploy, and operationalize machine learning models seamlessly within your Fabric experience. It integrates with Azure Machine Learning to provide built-in experiment tracking and model registry. Data scientists are empowered to enrich organizational data with predictions and allow business analysts to integrate those predictions into their BI reports. This way it shifts from descriptive to predictive insights. For more information, see [What is Data science in Microsoft Fabric?](../data-science/data-science-overview.md)- **Data Warehouse** - Data Warehouse experience provides industry leading SQL performance and scale. It fully separates compute from storage, enabling independent scaling of both the components. Additionally, it natively stores data in the open Delta Lake format. For more information, see [What is data warehousing in Microsoft Fabric?](../data-warehouse/data-warehousing.md)- **Real-Time Analytics** - Observational data, which is collected from various sources such as apps, IoT devices, human interactions, and so many more. It&#39;s currently the fastest growing data category. This data is often semi-structured in formats like JSON or Text. It comes in at high volume, with shifting schemas. These characteristics make it hard for traditional data warehousing platforms to work with. Real-Time Analytics is best in class engine for observational data analytics. For more information, see [What is Real-Time Analytics in Fabric?](../real-time-analytics/overview.md)- **Power BI** - Power BI is the world&#39;s leading Business Intelligence platform. It ensures that business owners can access all the data in Fabric quickly and intuitively to make better decisions with data. For more information, see [What is Power BI?](/power-bi/fundamentals/power-bi-overview)Fabric brings together all these experiences into a unified platform to offer the most comprehensive big data analytics platform in the industry.Microsoft Fabric enables organizations, and individuals, to turn large and complex data repositories into actionable workloads and analytics, and is an implementation of data mesh architecture. To learn more about data mesh, visit the article that explains [data mesh architecture](/azure/cloud-adoption-framework/scenarios/cloud-scale-analytics/architectures/what-is-data-mesh).</pre></div></td></tr></tbody></table></div></details></td></tr><tr><td>3</td><td><details class=\"dni-treeview\"><summary><span class=\"dni-code-hint\"><code>Submission#12+KBContent</code></span></summary><div><table><thead><tr></tr></thead><tbody><tr><td>KB</td><td><div class=\"dni-plaintext\"><pre>OneLake and lakehouse - the unification of lakehouses</pre></div></td></tr><tr><td>Content</td><td><div class=\"dni-plaintext\"><pre>The Microsoft Fabric platform unifies the OneLake and lakehouse architecture across the enterprises.OneLakeThe data lake is the foundation on which all the Fabric services are built. Microsoft Fabric Lake is also known as [OneLake](../onelake/onelake-overview.md). It&#39;s built into the Fabric service and provides a unified location to store all organizational data where the experiences operate.OneLake is built on top of ADLS (Azure Data Lake Storage) Gen2. It provides a single SaaS experience and a tenant-wide store for data that serves both professional and citizen developers. The OneLake SaaS experience simplifies the experiences, eliminating the need for users to understand any infrastructure concepts such as resource groups, RBAC (Role-Based Access Control), Azure Resource Manager, redundancy, or regions. Additionally it doesn&#39;t require the user to even have an Azure account.OneLake eliminates today&#39;s pervasive and chaotic data silos, which individual developers create when they provision and configure their own isolated storage accounts. Instead, OneLake provides a single, unified storage system for all developers, where discovery and data sharing is trivial and compliance with policy and security settings are enforced centrally and uniformly. For more information, see [What is OneLake?](../onelake/onelake-overview.md)Organizational structure of OneLake and lakehouseOneLake is hierarchical in nature to simplify management across your organization. It&#39;s built into Microsoft Fabric and there&#39;s no requirement for any up-front provisioning. There&#39;s only one OneLake per tenant and it provides a single-pane-of-glass file-system namespace that spans across users, regions and even clouds. The data in OneLake is divided into manageable containers for easy handling.The tenant maps to the root of OneLake and is at the top level of the hierarchy. You can create any number of workspaces within a tenant, which can be thought of as folders.The following image shows the various Fabric items where data is stored. It&#39;s an example of how various items within Fabric would store data inside OneLake. As displayed, you can create multiple workspaces within a tenant, create multiple lakehouses within each workspace. A lakehouse is a collection of files, folders, and tables that represents a database over a data lake. To learn more, see [What is a lakehouse?](../data-engineering/lakehouse-overview.md).Every developer and business unit in the tenant can instantly create their own workspaces in OneLake. They can ingest data into their own lakehouses, start processing, analyzing, and collaborating on the data, just like OneDrive in Office.All the Microsoft Fabric compute experiences are prewired to OneLake, just like the Office applications are prewired to use the organizational OneDrive. The experiences such as Data Engineering, Data Warehouse, Data Factory, Power BI, and Real-Time Analytics use OneLake as their native store. They don&#39;t need any extra configuration.OneLake is designed to allow instant mounting of existing PaaS storage accounts into OneLake with the [Shortcut](../onelake/onelake-shortcuts.md) feature. There&#39;s no need to migrate or move any of the existing data. Using shortcuts, you can access the data stored in Azure Data Lake Storage.Additionally, shortcuts allow you to easily share data between users and applications without moving or duplicating information. The shortcut capability extends to other storage systems, allowing you to compose and analyze data across clouds with transparent, intelligent caching that reduces egress costs and brings data closer to compute.</pre></div></td></tr></tbody></table></div></details></td></tr></tbody></table><style>\r\n",
       ".dni-code-hint {\r\n",
       "    font-style: italic;\r\n",
       "    overflow: hidden;\r\n",
       "    white-space: nowrap;\r\n",
       "}\r\n",
       ".dni-treeview {\r\n",
       "    white-space: nowrap;\r\n",
       "}\r\n",
       ".dni-treeview td {\r\n",
       "    vertical-align: top;\r\n",
       "    text-align: start;\r\n",
       "}\r\n",
       "details.dni-treeview {\r\n",
       "    padding-left: 1em;\r\n",
       "}\r\n",
       "table td {\r\n",
       "    text-align: start;\r\n",
       "}\r\n",
       "table tr { \r\n",
       "    vertical-align: top; \r\n",
       "    margin: 0em 0px;\r\n",
       "}\r\n",
       "table tr td pre \r\n",
       "{ \r\n",
       "    vertical-align: top !important; \r\n",
       "    margin: 0em 0px !important;\r\n",
       "} \r\n",
       "table th {\r\n",
       "    text-align: start;\r\n",
       "}\r\n",
       "</style>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "kbList"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "dotnet_interactive": {
     "language": "csharp"
    },
    "polyglot_notebook": {
     "kernelName": "csharp"
    },
    "vscode": {
     "languageId": "polyglot-notebook"
    }
   },
   "outputs": [],
   "source": [
    "var vectorData =  new List<KBContent>();\n",
    "\n",
    "int stepsCount = 0;\n",
    "\n",
    "foreach(var item in kbList)\n",
    "{\n",
    "    if(item.KB!=\"\")\n",
    "    {\n",
    "        vectorData.Add(item);\n",
    "    }\n",
    "    else\n",
    "    {\n",
    "        if(vectorData.Count!=0)\n",
    "        {\n",
    "            vectorData[vectorData.Count-1].Content += item.Content;\n",
    "        }\n",
    "    }\n",
    "\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "dotnet_interactive": {
     "language": "csharp"
    },
    "polyglot_notebook": {
     "kernelName": "csharp"
    },
    "vscode": {
     "languageId": "polyglot-notebook"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table><thead><tr><th><i>index</i></th><th>value</th></tr></thead><tbody><tr><td>0</td><td><details class=\"dni-treeview\"><summary><span class=\"dni-code-hint\"><code>Submission#12+KBContent</code></span></summary><div><table><thead><tr></tr></thead><tbody><tr><td>KB</td><td><div class=\"dni-plaintext\"><pre>What is Microsoft Fabric?</pre></div></td></tr><tr><td>Content</td><td><div class=\"dni-plaintext\"><pre>Microsoft Fabric is an all-in-one analytics solution for enterprises that covers everything from data movement to data science, Real-Time Analytics, and business intelligence. It offers a comprehensive suite of services, including data lake, data engineering, and data integration, all in one place.With Fabric, you don&#39;t need to piece together different services from multiple vendors. Instead, you can enjoy a highly integrated, end-to-end, and easy-to-use product that is designed to simplify your analytics needs.The platform is built on a foundation of Software as a Service (SaaS), which takes simplicity and integration to a whole new level.</pre></div></td></tr></tbody></table></div></details></td></tr><tr><td>1</td><td><details class=\"dni-treeview\"><summary><span class=\"dni-code-hint\"><code>Submission#12+KBContent</code></span></summary><div><table><thead><tr></tr></thead><tbody><tr><td>KB</td><td><div class=\"dni-plaintext\"><pre>SaaS foundation</pre></div></td></tr><tr><td>Content</td><td><div class=\"dni-plaintext\"><pre>Microsoft Fabric brings together new and existing components from Power BI, Azure Synapse, and Azure Data Explorer into a single integrated environment. These components are then presented in various customized user experiences.Fabric brings together experiences such as Data Engineering, Data Factory, Data Science, Data Warehouse, Real-Time Analytics, and Power BI onto a shared SaaS foundation. This integration provides the following advantages:- An extensive range of deeply integrated analytics in the industry.- Shared experiences across experiences that are familiar and easy to learn.- Developers can easily access and reuse all assets.- A unified data lake that allows you to retain the data where it is while using your preferred analytics tools.- Centralized administration and governance across all experiences.With the Microsoft Fabric SaaS experience, all the data and the services are seamlessly integrated. IT teams can centrally configure core enterprise capabilities and permissions are automatically applied across all the underlying services. Additionally, data sensitivity labels are inherited automatically across the items in the suite.Fabric allows creators to concentrate on producing their best work, freeing them from the need to integrate, manage, or understand the underlying infrastructure that supports the experience.</pre></div></td></tr></tbody></table></div></details></td></tr><tr><td>2</td><td><details class=\"dni-treeview\"><summary><span class=\"dni-code-hint\"><code>Submission#12+KBContent</code></span></summary><div><table><thead><tr></tr></thead><tbody><tr><td>KB</td><td><div class=\"dni-plaintext\"><pre>Components of Microsoft Fabric</pre></div></td></tr><tr><td>Content</td><td><div class=\"dni-plaintext\"><pre>Microsoft Fabric offers the comprehensive set of analytics experiences designed to work together seamlessly. Each experience is tailored to a specific persona and a specific task. Fabric includes industry-leading experiences in the following categories for an end-to-end analytical need.- **Data Engineering** - Data Engineering experience provides a world class Spark platform with great authoring experiences, enabling data engineers to perform large scale data transformation and democratize data through the lakehouse. Microsoft Fabric Spark&#39;s integration with Data Factory enables notebooks and spark jobs to be scheduled and orchestrated. For more information, see [What is Data engineering in Microsoft Fabric?](../data-engineering/data-engineering-overview.md)- **Data Factory** - Azure Data Factory combines the simplicity of Power Query with the scale and power of Azure Data Factory. You can use more than 200 native connectors to connect to data sources on-premises and in the cloud. For more information, see [What is Data Factory in Microsoft Fabric?](../data-factory/data-factory-overview.md)- **Data Science** - Data Science experience enables you to build, deploy, and operationalize machine learning models seamlessly within your Fabric experience. It integrates with Azure Machine Learning to provide built-in experiment tracking and model registry. Data scientists are empowered to enrich organizational data with predictions and allow business analysts to integrate those predictions into their BI reports. This way it shifts from descriptive to predictive insights. For more information, see [What is Data science in Microsoft Fabric?](../data-science/data-science-overview.md)- **Data Warehouse** - Data Warehouse experience provides industry leading SQL performance and scale. It fully separates compute from storage, enabling independent scaling of both the components. Additionally, it natively stores data in the open Delta Lake format. For more information, see [What is data warehousing in Microsoft Fabric?](../data-warehouse/data-warehousing.md)- **Real-Time Analytics** - Observational data, which is collected from various sources such as apps, IoT devices, human interactions, and so many more. It&#39;s currently the fastest growing data category. This data is often semi-structured in formats like JSON or Text. It comes in at high volume, with shifting schemas. These characteristics make it hard for traditional data warehousing platforms to work with. Real-Time Analytics is best in class engine for observational data analytics. For more information, see [What is Real-Time Analytics in Fabric?](../real-time-analytics/overview.md)- **Power BI** - Power BI is the world&#39;s leading Business Intelligence platform. It ensures that business owners can access all the data in Fabric quickly and intuitively to make better decisions with data. For more information, see [What is Power BI?](/power-bi/fundamentals/power-bi-overview)Fabric brings together all these experiences into a unified platform to offer the most comprehensive big data analytics platform in the industry.Microsoft Fabric enables organizations, and individuals, to turn large and complex data repositories into actionable workloads and analytics, and is an implementation of data mesh architecture. To learn more about data mesh, visit the article that explains [data mesh architecture](/azure/cloud-adoption-framework/scenarios/cloud-scale-analytics/architectures/what-is-data-mesh).</pre></div></td></tr></tbody></table></div></details></td></tr><tr><td>3</td><td><details class=\"dni-treeview\"><summary><span class=\"dni-code-hint\"><code>Submission#12+KBContent</code></span></summary><div><table><thead><tr></tr></thead><tbody><tr><td>KB</td><td><div class=\"dni-plaintext\"><pre>OneLake and lakehouse - the unification of lakehouses</pre></div></td></tr><tr><td>Content</td><td><div class=\"dni-plaintext\"><pre>The Microsoft Fabric platform unifies the OneLake and lakehouse architecture across the enterprises.OneLakeThe data lake is the foundation on which all the Fabric services are built. Microsoft Fabric Lake is also known as [OneLake](../onelake/onelake-overview.md). It&#39;s built into the Fabric service and provides a unified location to store all organizational data where the experiences operate.OneLake is built on top of ADLS (Azure Data Lake Storage) Gen2. It provides a single SaaS experience and a tenant-wide store for data that serves both professional and citizen developers. The OneLake SaaS experience simplifies the experiences, eliminating the need for users to understand any infrastructure concepts such as resource groups, RBAC (Role-Based Access Control), Azure Resource Manager, redundancy, or regions. Additionally it doesn&#39;t require the user to even have an Azure account.OneLake eliminates today&#39;s pervasive and chaotic data silos, which individual developers create when they provision and configure their own isolated storage accounts. Instead, OneLake provides a single, unified storage system for all developers, where discovery and data sharing is trivial and compliance with policy and security settings are enforced centrally and uniformly. For more information, see [What is OneLake?](../onelake/onelake-overview.md)Organizational structure of OneLake and lakehouseOneLake is hierarchical in nature to simplify management across your organization. It&#39;s built into Microsoft Fabric and there&#39;s no requirement for any up-front provisioning. There&#39;s only one OneLake per tenant and it provides a single-pane-of-glass file-system namespace that spans across users, regions and even clouds. The data in OneLake is divided into manageable containers for easy handling.The tenant maps to the root of OneLake and is at the top level of the hierarchy. You can create any number of workspaces within a tenant, which can be thought of as folders.The following image shows the various Fabric items where data is stored. It&#39;s an example of how various items within Fabric would store data inside OneLake. As displayed, you can create multiple workspaces within a tenant, create multiple lakehouses within each workspace. A lakehouse is a collection of files, folders, and tables that represents a database over a data lake. To learn more, see [What is a lakehouse?](../data-engineering/lakehouse-overview.md).Every developer and business unit in the tenant can instantly create their own workspaces in OneLake. They can ingest data into their own lakehouses, start processing, analyzing, and collaborating on the data, just like OneDrive in Office.All the Microsoft Fabric compute experiences are prewired to OneLake, just like the Office applications are prewired to use the organizational OneDrive. The experiences such as Data Engineering, Data Warehouse, Data Factory, Power BI, and Real-Time Analytics use OneLake as their native store. They don&#39;t need any extra configuration.OneLake is designed to allow instant mounting of existing PaaS storage accounts into OneLake with the [Shortcut](../onelake/onelake-shortcuts.md) feature. There&#39;s no need to migrate or move any of the existing data. Using shortcuts, you can access the data stored in Azure Data Lake Storage.Additionally, shortcuts allow you to easily share data between users and applications without moving or duplicating information. The shortcut capability extends to other storage systems, allowing you to compose and analyze data across clouds with transparent, intelligent caching that reduces egress costs and brings data closer to compute.</pre></div></td></tr></tbody></table></div></details></td></tr></tbody></table><style>\r\n",
       ".dni-code-hint {\r\n",
       "    font-style: italic;\r\n",
       "    overflow: hidden;\r\n",
       "    white-space: nowrap;\r\n",
       "}\r\n",
       ".dni-treeview {\r\n",
       "    white-space: nowrap;\r\n",
       "}\r\n",
       ".dni-treeview td {\r\n",
       "    vertical-align: top;\r\n",
       "    text-align: start;\r\n",
       "}\r\n",
       "details.dni-treeview {\r\n",
       "    padding-left: 1em;\r\n",
       "}\r\n",
       "table td {\r\n",
       "    text-align: start;\r\n",
       "}\r\n",
       "table tr { \r\n",
       "    vertical-align: top; \r\n",
       "    margin: 0em 0px;\r\n",
       "}\r\n",
       "table tr td pre \r\n",
       "{ \r\n",
       "    vertical-align: top !important; \r\n",
       "    margin: 0em 0px !important;\r\n",
       "} \r\n",
       "table th {\r\n",
       "    text-align: start;\r\n",
       "}\r\n",
       "</style>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "vectorData"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **ðŸ”‘ Key: VectorDB**\n",
    "\n",
    "We need to store knowledge in the vector database and query through the vector database. Here is a simple example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "dotnet_interactive": {
     "language": "csharp"
    },
    "polyglot_notebook": {
     "kernelName": "csharp"
    },
    "vscode": {
     "languageId": "polyglot-notebook"
    }
   },
   "outputs": [],
   "source": [
    "string conceptCollectionName = \"fbkb-concept\";"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "dotnet_interactive": {
     "language": "csharp"
    },
    "polyglot_notebook": {
     "kernelName": "csharp"
    },
    "vscode": {
     "languageId": "polyglot-notebook"
    }
   },
   "outputs": [],
   "source": [
    "#pragma warning disable SKEXP0052\n",
    "#pragma warning disable CS1061\n",
    "#pragma warning disable SKEXP0011\n",
    "#pragma warning disable SKEXP0026\n",
    "\n",
    "var qdrantMemoryBuilder = new MemoryBuilder();\n",
    "\n",
    "var textEmbedding = new AzureOpenAITextEmbeddingGeneration(\"Your Azure OpenAI Services text-embedding-ada-002 Deployment Name\",\"text-embedding-ada-002\", \"Your Azure OpenAI Services Endpoint\", \"Your Azure OpenAI Services API Key\");\n",
    "\n",
    "qdrantMemoryBuilder.WithTextEmbeddingGeneration(textEmbedding);\n",
    "qdrantMemoryBuilder.WithQdrantMemoryStore(\"Your Qdrant endpoint\", 1536);\n",
    "\n",
    "var qdrantBuilder = qdrantMemoryBuilder.Build();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "dotnet_interactive": {
     "language": "csharp"
    },
    "polyglot_notebook": {
     "kernelName": "csharp"
    },
    "vscode": {
     "languageId": "polyglot-notebook"
    }
   },
   "outputs": [],
   "source": [
    "int vectorCount = 1000;\n",
    "\n",
    "foreach(var item in vectorData)\n",
    "{\n",
    "  await qdrantBuilder.SaveInformationAsync(conceptCollectionName, id: \"id\"+vectorCount.ToString(), text: item.KB+\" \"+ item.Content);\n",
    "  vectorCount++;\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "dotnet_interactive": {
     "language": "csharp"
    },
    "polyglot_notebook": {
     "kernelName": "csharp"
    },
    "vscode": {
     "languageId": "polyglot-notebook"
    }
   },
   "outputs": [],
   "source": [
    "string questionText = \"What is Mircorosft Fabric ?\"; "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The key to vector search is to find approximate matching vector content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "dotnet_interactive": {
     "language": "csharp"
    },
    "polyglot_notebook": {
     "kernelName": "csharp"
    },
    "vscode": {
     "languageId": "polyglot-notebook"
    }
   },
   "outputs": [],
   "source": [
    "var searchResults =  qdrantBuilder.SearchAsync(conceptCollectionName, questionText, limit: 1, minRelevanceScore: 0.7);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "dotnet_interactive": {
     "language": "csharp"
    },
    "polyglot_notebook": {
     "kernelName": "csharp"
    },
    "vscode": {
     "languageId": "polyglot-notebook"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "What is Microsoft Fabric? Microsoft Fabric is an all-in-one analytics solution for enterprises that covers everything from data movement to data science, Real-Time Analytics, and business intelligence. It offers a comprehensive suite of services, including data lake, data engineering, and data integration, all in one place.With Fabric, you don't need to piece together different services from multiple vendors. Instead, you can enjoy a highly integrated, end-to-end, and easy-to-use product that is designed to simplify your analytics needs.The platform is built on a foundation of Software as a Service (SaaS), which takes simplicity and integration to a whole new level. : 0.8197839\n"
     ]
    }
   ],
   "source": [
    "\n",
    "string result = \"\";\n",
    "await foreach (var item in searchResults)\n",
    "{\n",
    "    result = item.Metadata.Text;\n",
    "    Console.WriteLine(item.Metadata.Text + \" : \" + item.Relevance);\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **âœ… Summary**\n",
    "\n",
    "We can inject content knowledge into LLM by combining Chunking and vector database. What we need to consider is how to combine the content with the model for optimization. So what needs to be more is the content of Promptã€‚ Learn more about [link](https://learn.microsoft.com/en-us/semantic-kernel/prompt-engineering/)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
